{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: an√°lisis morfol√≥gico y aplicaci√≥n a opiniones sobre pel√≠culas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/drama.png\" style=\"width:400px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a utilizar cr√≠ticas escritas en [IMDB](http://www.imdb.com/) para tratar de extraer autom√°ticamente la opini√≥n expresada, positiva o negativa, de un texto. Para ello utilizamos algunas t√©cnicas t√©cnicas de an√°lisis morfol√≥gico del texto.\n",
    "\n",
    "El objetivo del ejercicio es construir un sistema que dado el texto en ingl√©s de una cr√≠tica sea capaz de estimar si esa cr√≠tica expresa una opini√≥n positiva o negativa. Empezaremos construyendo un clasificador de opini√≥n sencillo, para ir introduciendo caracter√≠sticas cada vez m√°s complicadas e ir mejorando nuestros resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de este cuaderno encontrar√°s celdas vac√≠as que tendr√°s que rellenar con tu propio c√≥digo. Sigue las instrucciones del cuaderno y presta especial atenci√≥n a los siguientes iconos:\n",
    "\n",
    "<table>\n",
    "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Deber√°s responder a la pregunta indicada con el c√≥digo o contestaci√≥n que escribas en la celda inferior.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Esto es una pista u observaci√≥n que te puede ayudar a resolver la pr√°ctica.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Este es un ejercicio avanzado y voluntario que puedes realizar si quieres profundar m√°s sobre el tema. Te animamos a intentarlo para aprender m√°s ¬°√Ånimo!</td></tr>\n",
    "</table>\n",
    "\n",
    "Para evitar problemas de compatibilidad y de paquetes no instalados, se recomienda ejecutar este notebook bajo uno de los [entornos recomendados de Text Mining](https://github.com/albarji/teaching-environments/tree/master/textmining).\n",
    "\n",
    "Adicionalmente si necesitas consultar la ayuda de cualquier funci√≥n python puedes colocar el cursor de escritura sobre el nombre de la misma y pulsar May√∫sculas+Shift para que aparezca un recuadro con sus detalles. Ten en cuenta que esto √∫nicamente funciona en las celdas de c√≥digo.\n",
    "\n",
    "¬°Adelante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a fijar la semilla aleatoria para que los resultados sean reproducibles entre diferentes ejecuciones del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparaci√≥n de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que usaremos en esta pr√°ctica son un conjunto preparado de los datos empleados en el art√≠culo\n",
    "\n",
    "    Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).\n",
    "    \n",
    "y consisten en cr√≠ticas de pel√≠culas escritas en la web en ingl√©s IMDB. Se han tomado aquellas cr√≠ticas con una puntuaci√≥n mayor a 7 como **opiniones positivas**, mientras que aquellas con puntuaci√≥n menor a 4 se han tomado como **opiniones negativas**.\n",
    "\n",
    "Los datos est√°n todos contenidos en el fichero *data/data.csv*, en formato CSV separado por tabuladores. El fichero contiene √∫nicamente dos columnas, la primera de ellas indicando el tipo de opini√≥n (1 = opini√≥n positiva, 0 = opini√≥n negativa) y la segunda de ellas el texto de la cr√≠tica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "      Carga en un Dataframe de Pandas los datos del fichero <i>data/data.csv</i>. Analiza los primeros registros del Dataframe. ¬øParecen coherentes los valores de opini√≥n con el texto?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  I simply cant understand why all these relics ...\n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...\n",
       "2          1  It could have been a better film. It does drag...\n",
       "3          1  It is very hard to rate this film. As entertai...\n",
       "4          1  I've read some terrible things about this film..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/data.csv\", sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    El fichero cargado arriba es una versi√≥n reducida del conjunto completo de datos. Si quieres optar por usar todos los datos para esta pr√°ctica puedes cargar el fichero <i>data/datafull.csv.gz</i>. Ten en cuenta que los tiempos de c√°lculo ser√°n mucho mayores, aunque a cambio podr√°s conseguir mejores resultados de clasificaci√≥n.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "#data = pd.read_csv(\"./data/datafull.csv\", sep='\\t')\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a preparar dos listas de √≠ndices, que nos indiquen qu√© parte de los datos vamos a usar para entrenamiento y qu√© parte para test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Genera dos listas, una conteniendo los √≠ndices de la primera mitad de las filas del DataFrame de datos (√≠ndices de train), y otra conteniendo los √≠ndices de la otra mitad (√≠ndices de test).\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import math\n",
    "nrows = data.shape[0]\n",
    "splitpoint = math.floor(nrows * 0.50)\n",
    "trainidx = list(range(splitpoint))\n",
    "testidx = list(range(splitpoint, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder valorar si las t√©cnicas avanzadas que vamos a emplear aportan algo de utilidad a este problema, vamos a empezar con una soluci√≥n muy sencilla basada en bag of words, estimando la precisi√≥n de clasificaci√≥n que podemos obtener con ella y usando este valor como referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Utilizando lo que has aprendido en la pr√°ctica anterior, construye un sistema de clasificaci√≥n basado en unigramas de palabras que aprenda de los datos de entrenamiento, y calcula el error de estimaci√≥n en test del mismo. Como modelo de clasificaci√≥n utiliza una SVM lineal, con sus par√°metros por defecto. No realices ning√∫n proceso de b√∫squeda para optimizar los par√°metros del modelo (tipo GridSearchCV).\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LinearSVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'vectorizer__analyzer' : ['word'],\n",
    "    'vectorizer__ngram_range' : [(1, 1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, params, n_jobs = 7)\n",
    "\n",
    "model.fit(data[\"text\"][trainidx].values, data[\"sentiment\"][trainidx])\n",
    "model.score(data[\"text\"][testidx].values, data[\"sentiment\"][testidx])\n",
    "\n",
    "# 0.80 con datos peque√±os\n",
    "# 0.88544 con datos grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    El nivel de precisi√≥n que has obtenido, ¬øcrees que ser√≠a adecuado para una aplicaci√≥n real? ¬øPiensas que puede mejorarse?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis morfosint√°tico con spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En entornos donde existe mucho texto expresado de forma natural lo habitual es que una palabra aparezca con diversas conjugaciones y formas, sin que el significado final del texto cambie demasiado (salvo matices que discutiremos m√°s adelante). En estos casos un paso de preprocesamiento habitual es convertir las palabras a lemas, o eliminar categor√≠as morfol√≥gicas que aportan poca informaci√≥n. Para esto es imprescindible realizar un **an√°lisis morfosint√°ctico** del texto, lo cual podemos hacer f√°cilmente para diversos idiomas utilizando la librer√≠a **spaCy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy utiliza modelos morfosint√°cticos espec√≠ficos para cada idioma. Por defecto la librer√≠a no incluye ning√∫n modelo, pero podemos instalarlo de manera sencilla con comandos a python. La siguiente l√≠nea ejecuta un comando de sistema para instalar el modelo de spaCy para el idioma ingl√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
      "     -----------                          123.9/400.7 MB 611.1 kB/s eta 0:07:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Wheel 'en-core-web-lg' located at C:\\Users\\agoni\\AppData\\Local\\Temp\\pip-unpack-u418ta8m\\en_core_web_lg-3.3.0-py3-none-any.whl is invalid.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Si el comando anterior produce un error relacionado con la falta de permisos, deber√°s ejecutarlo desde una terminal de Anaconda lanzada con permisos de administrador.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenido el modelo, podemos cargarlo en memoria con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y analizar una frase de ejemplo de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"They killed the man with a gun.\"\n",
    "doc = nlp(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"The black cat sat peacefully on the mat.\"\n",
    "doc = nlp(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**doc** es ahora una versi√≥n de la frase que contiene toda la informaci√≥n morfol√≥gica y sint√°ctica extra√≠da por el analizador. Podemos iterar sobre cada uno de los tokens de la frase de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The\n",
      "Token: black\n",
      "Token: cat\n",
      "Token: sat\n",
      "Token: peacefully\n",
      "Token: on\n",
      "Token: the\n",
      "Token: mat\n",
      "Token: .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"Token:\", token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente podemos acceder a cada uno de los tokens por su posici√≥n en la frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(doc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero lo m√°s interesante son los diferentes campos con informaci√≥n extra que contiene cada token. Campos como\n",
    "* *texto*: texto original\n",
    "* *lemma_*: lema\n",
    "* *pos_*: Part of Speech (categor√≠a morfol√≥gica) simple\n",
    "* *tag_*: categor√≠a morfol√≥gica detallada\n",
    "* *shape_*: patr√≥n de may√∫sculas/min√∫sculas\n",
    "* *is_alpha*: si el token se componente de caracteres alfab√©ticos\n",
    "* *is_stop*: si el token ha sido detectado como una stopword\n",
    "* *head*: token padre en el √°rbol de dependencia\n",
    "* *dep_*: relaci√≥n sint√°ctica con el token padre\n",
    "* etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, vamos a imprimir toda esta informaci√≥n para el primer token de la frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: The\n",
      "Lema: the\n",
      "POS: DET\n",
      "Tag: DT\n",
      "Forma: Xxx\n",
      "Es alpha: True\n",
      "Es stopword: True\n",
      "Token padre: cat\n",
      "Relaci√≥n sint√°ctica: det\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(\"Texto:\", token.text)\n",
    "print(\"Lema:\", token.lemma_)\n",
    "print(\"POS:\", token.pos_)\n",
    "print(\"Tag:\", token.tag_)\n",
    "print(\"Forma:\", token.shape_)\n",
    "print(\"Es alpha:\", token.is_alpha)\n",
    "print(\"Es stopword:\", token.is_stop)\n",
    "print(\"Token padre:\", token.head)\n",
    "print(\"Relaci√≥n sint√°ctica:\", token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer esto con toda la frase y mostrarlo como una tabla (DataFrame) para mayor claridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lema</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "      <th>shap</th>\n",
       "      <th>isalpha</th>\n",
       "      <th>isstop</th>\n",
       "      <th>padre</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>cat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cat</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sat</td>\n",
       "      <td>sit</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peacefully</td>\n",
       "      <td>peacefully</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sat</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>mat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mat</td>\n",
       "      <td>mat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>on</td>\n",
       "      <td>pobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token        lema    POS  tag  shap  isalpha  isstop padre     dep\n",
       "0         The         the    DET   DT   Xxx     True    True   cat     det\n",
       "1       black       black    ADJ   JJ  xxxx     True   False   cat    amod\n",
       "2         cat         cat   NOUN   NN   xxx     True   False   sat   nsubj\n",
       "3         sat         sit   VERB  VBD   xxx     True   False   sat    ROOT\n",
       "4  peacefully  peacefully    ADV   RB  xxxx     True   False   sat  advmod\n",
       "5          on          on    ADP   IN    xx     True    True   sat    prep\n",
       "6         the         the    DET   DT   xxx     True    True   mat     det\n",
       "7         mat         mat   NOUN   NN   xxx     True   False    on    pobj\n",
       "8           .           .  PUNCT    .     .    False   False   sat   punct"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"token\", \"lema\", \"POS\", \"tag\", \"shap\", \"isalpha\", \"isstop\", \"padre\", \"dep\"],\n",
    "    data=[[token.text, token.lemma_, token.pos_, token.tag_,\n",
    "          token.shape_, token.is_alpha, token.is_stop, token.head, token.dep_]\n",
    "          for token in doc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n podemos visualizar el √°rbol sint√°tico de dependencias usando la utilidad **displaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ce2707aa8577462398eaea8a9d8c5a01-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">black</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">peacefully</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">mat.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ce2707aa8577462398eaea8a9d8c5a01-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ce2707aa8577462398eaea8a9d8c5a01-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto, el an√°lisis morfosint√°ctico de spaCy nos proporciona mucha informaci√≥n, pero tambi√©n puede ser costoso de realizar cuando tenemos gran cantidad de textos. Si no necesitamos de todos los componentes del an√°lisis, podemos acelerar el tiempo de c√°lculo desactivando algunos elementos del proceso. Por ejemplo, cargando de nuevo el modelo de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpfast = spacy.load('en_core_web_lg', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto tenemos un analizador morfosint√°ctico que no realiza detecci√≥n de entidades (`ner`) ni an√°lisis del √°rbol sint√°ctico de dependencias (`parser`), pero que a cambio ejecuta a mayor velocidad, como podemos comprobar en las siguientes dos celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    nlp(\"The black cat sat peacefully on the mat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 77.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    nlpfast(\"The black cat sat peacefully on the mat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto el funcionamiento de spaCy, vamos a pasar a ejecutar el an√°lisis morfosint√°ctico para cada texto de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Crea una nueva columna en el DataFrame de datos que contenga una versi√≥n analizada con spaCy del texto correspondiente. Es suficiente con que apliques el objeto <b>nlp</b> a cada texto y guardes el resultado.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>analyzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "      <td>(I, simply, ca, nt, understand, why, all, thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "      <td>(Director, Raoul, Walsh, was, like, the, Micha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "      <td>(It, could, have, been, a, better, film, ., It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "      <td>(It, is, very, hard, to, rate, this, film, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "      <td>(I, 've, read, some, terrible, things, about, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  I simply cant understand why all these relics ...   \n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...   \n",
       "2          1  It could have been a better film. It does drag...   \n",
       "3          1  It is very hard to rate this film. As entertai...   \n",
       "4          1  I've read some terrible things about this film...   \n",
       "\n",
       "                                            analyzed  \n",
       "0  (I, simply, ca, nt, understand, why, all, thes...  \n",
       "1  (Director, Raoul, Walsh, was, like, the, Micha...  \n",
       "2  (It, could, have, been, a, better, film, ., It...  \n",
       "3  (It, is, very, hard, to, rate, this, film, ., ...  \n",
       "4  (I, 've, read, some, terrible, things, about, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "def addanalyzed(df):\n",
    "    analyzed = [nlp(text) for text in df[\"text\"]]\n",
    "    df[\"analyzed\"] = pd.Series(analyzed, index = df.index)\n",
    "    \n",
    "addanalyzed(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado por morfolog√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a sacar partido a la informaci√≥n morfol√≥gica que nos proporciona spaCy para mejorar el modelo predictivo. Para ello realizaremos dos operaciones:\n",
    "\n",
    "* Filtrar los textos para quedarnos solo con aquellas palabras de las categor√≠as morfol√≥gicas con m√°s carga de emoci√≥n.\n",
    "* Filtrar los textos para no incluir palabras stopwords.\n",
    "* Sustituir cada token por su lema, para as√≠ reducir el tama√±o del vocabulario y simplificar el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Crea una nueva columna en el DataFrame de datos que contenga una versi√≥n modificado del texto con √∫nicamente los lemas de aquellos tokens cuyas etiquetas POS sean de clase <b>nombre</b>, <b>verbo</b>, <b>adjetivo</b> o <b>adverbio</b>.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pos_ tag list\n",
    "\n",
    "- ADJ: adjective, e.g. big, old, green, incomprehensible, first\n",
    "- ADP: adposition, e.g. in, to, during\n",
    "- ADV: adverb, e.g. very, tomorrow, down, where, there\n",
    "- AUX: auxiliary, e.g. is, has (done), will (do), should (do)\n",
    "- CONJ: conjunction, e.g. and, or, but\n",
    "- CCONJ: coordinating conjunction, e.g. and, or, but\n",
    "- DET: determiner, e.g. a, an, the\n",
    "- INTJ: interjection, e.g. psst, ouch, bravo, hello\n",
    "- NOUN: noun, e.g. girl, cat, tree, air, beauty\n",
    "- NUM: numeral, e.g. 1, 2017, one, seventy-seven, IV, MMXIV\n",
    "- PART: particle, e.g. ‚Äôs, not,\n",
    "- PRON: pronoun, e.g I, you, he, she, myself, themselves, somebody\n",
    "- PROPN: proper noun, e.g. Mary, John, London, NATO, HBO\n",
    "- PUNCT: punctuation, e.g. ., (, ), ?\n",
    "- SCONJ: subordinating conjunction, e.g. if, while, that\n",
    "- SYM: symbol, e.g. $, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù\n",
    "- VERB: verb, e.g. run, runs, running, eat, ate, eating\n",
    "- X: other, e.g. sfpksdpsxmsa\n",
    "- SPACE: space, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>analyzed</th>\n",
       "      <th>posfilter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "      <td>(I, simply, ca, nt, understand, why, all, thes...</td>\n",
       "      <td>simply understand relic era refuse let clearly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "      <td>(Director, Raoul, Walsh, was, like, the, Micha...</td>\n",
       "      <td>year mean positive way definitely be bay hater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "      <td>(It, could, have, been, a, better, film, ., It...</td>\n",
       "      <td>well film drag point central story shift compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "      <td>(It, is, very, hard, to, rate, this, film, ., ...</td>\n",
       "      <td>hard rate film entertainment value 21st centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "      <td>(I, 've, read, some, terrible, things, about, ...</td>\n",
       "      <td>read terrible thing film prepare bad confusing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  I simply cant understand why all these relics ...   \n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...   \n",
       "2          1  It could have been a better film. It does drag...   \n",
       "3          1  It is very hard to rate this film. As entertai...   \n",
       "4          1  I've read some terrible things about this film...   \n",
       "\n",
       "                                            analyzed  \\\n",
       "0  (I, simply, ca, nt, understand, why, all, thes...   \n",
       "1  (Director, Raoul, Walsh, was, like, the, Micha...   \n",
       "2  (It, could, have, been, a, better, film, ., It...   \n",
       "3  (It, is, very, hard, to, rate, this, film, ., ...   \n",
       "4  (I, 've, read, some, terrible, things, about, ...   \n",
       "\n",
       "                                           posfilter  \n",
       "0  simply understand relic era refuse let clearly...  \n",
       "1  year mean positive way definitely be bay hater...  \n",
       "2  well film drag point central story shift compl...  \n",
       "3  hard rate film entertainment value 21st centur...  \n",
       "4  read terrible thing film prepare bad confusing...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "def addposfilter(df):\n",
    "    posfilter = [\" \".join([token.lemma_ for token in text \n",
    "                           if token.pos_ in {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"} and not token.is_stop]) \n",
    "                 for text in df[\"analyzed\"]]\n",
    "    df[\"posfilter\"] = pd.Series(posfilter, index = df.index)\n",
    "    \n",
    "addposfilter(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Repite los pasos que realizaste en el caso del modelo inicial (al inicio de esta pr√°ctica) para construir un nuevo modelo, esta vez basado en los textos que has preparados en lugar de los textos originales. Mide el nivel de score sobre el conjunto de test, ¬øhas conseguido alguna mejora en precisi√≥n? ¬øY en tiempos de entrenamiento?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LinearSVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'vectorizer__analyzer' : ['word'],\n",
    "    'vectorizer__ngram_range' : [(1, 1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, params, n_jobs = 7)\n",
    "model.fit(data[\"posfilter\"][trainidx].values, data[\"sentiment\"][trainidx])\n",
    "model.score(data[\"posfilter\"][testidx].values, data[\"sentiment\"][testidx])\n",
    "\n",
    "# Best small: 0.8088  (lemmas, filter stopwords)\n",
    "# Small: 0.8056 (lemmas, filter stopwords, filter pos NOUN VERB ADJ ADV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy con transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentaci√≥n √∫til:\n",
    "- Pipeline spacy: https://spacy.io/usage/spacy-101#pipelines\n",
    "- Se permite usar transformers a partir de spacy 3.0: https://spacy.io/usage/v3#features-transformers\n",
    "- Plantilla para crear configuraci√≥n para entrenar pipeline de spacy: https://spacy.io/usage/training#quickstart\n",
    "- Modelos de spacy: https://spacy.io/usage/models\n",
    "- Modelos de spacy subidos al repositorio de huggingface: https://huggingface.co/models?library=spacy&sort=downloads\n",
    "- Librer√≠a necesaria para usar spacy con transformers: https://github.com/explosion/spacy-transformers#-documentation\n",
    "\n",
    "A continuaci√≥n, dejo un ejemplo con un modelo transformer usando spacy en idioma ingl√©s: https://huggingface.co/spacy/en_core_web_trf?text=My+name+is+Sarah+and+I+live+in+London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-trf==any\n",
      "  Downloading https://huggingface.co/spacy/en_core_web_trf/resolve/main/en_core_web_trf-any-py3-none-any.whl (460.3 MB)\n",
      "     -------------------------------------- 460.3/460.3 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from en-core-web-trf==any) (1.1.8)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from en-core-web-trf==any) (3.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (1.0.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (8.1.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (1.23.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (63.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (4.64.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (0.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (1.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (1.10.2)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (0.8.5)\n",
      "Requirement already satisfied: transformers<4.22.0,>=3.4.0 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (4.21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (3.3)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp38-cp38-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (0.0.3)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\agoni\\appdata\\roaming\\python\\python38\\site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (0.10.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==any) (0.11.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-trf==any) (2.1.1)\n",
      "Installing collected packages: blis\n",
      "Successfully installed blis-0.7.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-lg 3.3.0 requires spacy<3.4.0,>=3.3.0.dev0, but you have spacy 3.4.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install https://huggingface.co/spacy/en_core_web_trf/resolve/main/en_core_web_trf-any-py3-none-any.whl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\textmining-labs-updated\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "# Using spacy.load().\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "# fast \n",
    "#nlpfast = spacy.load('en_core_web_trf', disable=['ner'])\n",
    "\n",
    "frase = \"The black cat sat peacefully on the mat.\"\n",
    "doc = nlp(frase)\n",
    "# fast\n",
    "#doc = nlpfast(frase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, podemos ver los pesos del modelo transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerData(wordpieces=WordpieceBatch(strings=[['<s>', 'The', 'ƒ†black', 'ƒ†cat', 'ƒ†sat', 'ƒ†peacefully', 'ƒ†on', 'ƒ†the', 'ƒ†mat', '.', '</s>']], input_ids=array([[    0,   133,   909,  4758,  4005, 17061,    15,     5,  7821,\n",
       "            4,     2]]), attention_mask=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32), lengths=[11], token_type_ids=None), model_output=ModelOutput([('last_hidden_state', array([[[-0.27488506,  0.09796198, -1.8045633 , ...,  0.8744784 ,\n",
       "          0.60974526, -0.2559871 ],\n",
       "        [-0.711131  , -0.28686467,  0.44341055, ..., -1.3029665 ,\n",
       "         -0.49502856, -1.1373456 ],\n",
       "        [ 0.5758208 ,  0.8377642 ,  0.25092873, ...,  2.373052  ,\n",
       "          0.36393455,  0.5141425 ],\n",
       "        ...,\n",
       "        [-0.17567575, -1.285404  ,  0.13782468, ...,  0.01760009,\n",
       "          0.42984828,  0.7407291 ],\n",
       "        [-0.51406217, -0.68828785, -1.2210158 , ...,  0.41192687,\n",
       "          0.57110304,  0.182773  ],\n",
       "        [-0.27524173,  0.09897848, -1.8029516 , ...,  0.8743955 ,\n",
       "          0.6094329 , -0.25603712]]], dtype=float32)), ('pooler_output', array([[ 3.88991266e-01,  5.39952338e-01, -3.31940949e-01,\n",
       "         2.78970987e-01, -3.64698857e-01, -3.64652753e-01,\n",
       "         4.40913260e-01, -4.29810822e-01, -6.34710371e-01,\n",
       "        -3.87374669e-01,  3.69419158e-01, -1.14237607e-01,\n",
       "         1.89164191e-01,  8.73278856e-01, -3.89296353e-01,\n",
       "         8.72737095e-02, -1.59561206e-02, -5.64816236e-01,\n",
       "         4.31832939e-01,  4.03178111e-02, -2.19458774e-01,\n",
       "         2.14270782e-02, -2.94734478e-01,  5.80796063e-01,\n",
       "        -9.17935595e-02,  4.97599304e-01, -3.33707690e-01,\n",
       "        -4.84491527e-01,  3.28349859e-01,  3.39817256e-01,\n",
       "         3.69395554e-01, -2.11546242e-01,  2.67967552e-01,\n",
       "         3.53919655e-01, -7.39223719e-01, -1.08397335e-01,\n",
       "         3.60646509e-02, -3.59264731e-01,  3.68295372e-01,\n",
       "        -1.07169002e-01, -4.47306037e-03, -9.32338163e-02,\n",
       "        -1.75361231e-01, -5.66253960e-01, -1.06652476e-01,\n",
       "         2.58854330e-01, -5.40644228e-02, -6.62579596e-01,\n",
       "         4.08282965e-01,  4.00534064e-01, -2.06736267e-01,\n",
       "         5.22966206e-01,  5.43954134e-01, -3.89567256e-01,\n",
       "        -4.61890906e-01,  3.81630361e-02,  2.83506811e-01,\n",
       "        -2.67523438e-01, -1.33108169e-01,  4.32753116e-02,\n",
       "        -2.14374647e-01, -7.52595901e-01, -2.43353084e-01,\n",
       "         3.22497666e-01, -8.59391749e-01, -5.89814037e-02,\n",
       "        -4.09920216e-01, -5.92250168e-01, -1.47797853e-01,\n",
       "         4.40657586e-01, -2.63157457e-01,  2.64668405e-01,\n",
       "         5.63395977e-01,  1.69130303e-02, -5.10717869e-01,\n",
       "         3.23947638e-01, -3.17422718e-01,  1.10726222e-01,\n",
       "        -2.54916288e-02,  5.26633859e-01, -6.39803410e-01,\n",
       "         8.64197835e-02,  1.25124931e-01,  4.12004411e-01,\n",
       "        -1.91597730e-01, -6.23231754e-02, -5.57721674e-01,\n",
       "        -1.09240822e-01, -1.71917811e-01,  1.07669547e-01,\n",
       "        -7.85514057e-01, -7.69993782e-01, -1.69511110e-01,\n",
       "        -1.99641958e-02, -7.79202223e-01,  6.81774179e-03,\n",
       "         5.63090563e-01, -2.28311494e-02, -1.60440519e-01,\n",
       "        -3.65840614e-01,  2.28823289e-01,  4.89468426e-01,\n",
       "        -3.76142591e-01,  4.52778339e-02,  5.30478477e-01,\n",
       "        -3.28832865e-02,  2.58043438e-01, -1.24325655e-01,\n",
       "        -5.15808072e-03,  3.04164261e-01, -5.16895466e-02,\n",
       "         3.13421190e-01, -9.47313756e-02,  3.86914879e-01,\n",
       "         3.85570943e-01,  4.10672277e-02,  4.22216237e-01,\n",
       "        -5.22526085e-01,  8.83819818e-01, -7.69522488e-01,\n",
       "         2.55818635e-01, -3.03365767e-01,  4.61852789e-01,\n",
       "         3.45095068e-01, -7.46431172e-01,  6.21372998e-01,\n",
       "         7.72816837e-01,  2.57881373e-01, -3.71255398e-01,\n",
       "        -3.58401388e-01, -4.25948024e-01,  5.38618386e-01,\n",
       "         4.33319956e-01,  3.05842105e-02,  3.59408349e-01,\n",
       "         6.27982199e-01, -6.59864247e-01, -8.51816963e-03,\n",
       "         2.51949459e-01, -2.83320695e-02,  1.02849357e-01,\n",
       "         2.37499163e-01,  6.93688169e-02, -7.14473054e-02,\n",
       "         2.51454502e-01, -3.46343756e-01,  4.49692905e-01,\n",
       "         2.85939574e-01, -5.96740425e-01,  4.36554193e-01,\n",
       "         1.81195304e-01, -3.84828687e-01, -3.74425352e-01,\n",
       "        -3.24300528e-01, -8.69013190e-01,  1.02144979e-01,\n",
       "        -2.45070726e-01,  4.82194871e-01, -1.05691656e-01,\n",
       "        -6.09802723e-01, -4.02879030e-01, -1.55686969e-02,\n",
       "        -4.35358107e-01, -6.83238447e-01, -3.30011874e-01,\n",
       "        -5.40119171e-01,  6.90787017e-01, -1.47243232e-01,\n",
       "        -3.18540752e-01, -6.75849542e-02, -7.84317404e-02,\n",
       "        -7.90498376e-01, -6.54649317e-01,  8.50956514e-02,\n",
       "        -3.49816382e-01,  7.35079348e-01, -4.07025605e-01,\n",
       "         6.90798640e-01,  5.54133952e-01, -5.26112854e-01,\n",
       "         1.11240700e-01, -2.58231480e-02,  4.19719338e-01,\n",
       "        -1.68394491e-01,  3.43459547e-01,  3.25746059e-01,\n",
       "         8.28241408e-02,  4.03035507e-02, -7.06968009e-01,\n",
       "        -5.68772793e-01, -2.12684214e-01, -1.29370734e-01,\n",
       "         4.29186016e-01,  2.35644013e-01, -1.25189517e-02,\n",
       "        -2.91247845e-01, -2.20170707e-01, -1.55989721e-01,\n",
       "         4.95462775e-01, -8.85097802e-01, -3.86969894e-01,\n",
       "        -5.00207603e-01,  3.96820635e-01, -3.38217825e-01,\n",
       "         3.58889192e-01,  4.25530791e-01,  3.19884539e-01,\n",
       "         6.45354092e-01, -2.60775298e-01, -6.78212404e-01,\n",
       "         2.10863769e-01, -4.51782554e-01,  5.68479955e-01,\n",
       "         1.15540437e-01, -8.30301344e-01, -4.18469459e-01,\n",
       "        -3.73615891e-01, -1.13843203e-01, -5.85189939e-01,\n",
       "         4.19809669e-01, -1.21082529e-01,  1.73687398e-01,\n",
       "        -2.39996642e-01, -4.40432012e-01,  3.98486793e-01,\n",
       "        -9.07042623e-02,  2.62998432e-01,  6.51874840e-01,\n",
       "        -1.46197125e-01,  1.45695731e-01,  6.91756308e-01,\n",
       "         1.57403395e-01, -1.74153358e-01, -1.58541769e-01,\n",
       "        -4.77055311e-02,  4.71073717e-01, -4.74498034e-01,\n",
       "         4.47418302e-01, -4.61082727e-01, -4.74980205e-01,\n",
       "         4.74468440e-01, -4.96991187e-01,  5.19667327e-01,\n",
       "        -2.68663317e-02, -3.67818296e-01, -3.73387188e-01,\n",
       "        -1.66980848e-01,  2.37444993e-02,  3.86096723e-02,\n",
       "        -4.95169103e-01,  1.80509090e-01, -5.56426466e-01,\n",
       "        -2.54196078e-01,  4.58877057e-01,  2.69611087e-02,\n",
       "         6.73312664e-01,  7.91947618e-02, -4.76870000e-01,\n",
       "        -4.86255363e-02,  7.88926855e-02, -1.78577229e-01,\n",
       "         3.31039310e-01, -1.53000250e-01,  6.03530288e-01,\n",
       "         2.73523360e-01,  6.41527414e-01,  4.91405547e-01,\n",
       "        -1.75543979e-01, -6.75102949e-01,  4.17230397e-01,\n",
       "         8.35942402e-02, -3.92138094e-01, -5.55224270e-02,\n",
       "        -9.71142054e-02, -4.11011688e-02,  8.65137279e-02,\n",
       "        -7.13252053e-02,  2.70609200e-01, -4.29081798e-01,\n",
       "        -1.14656016e-01, -3.06347847e-01,  4.56012860e-02,\n",
       "         4.00816113e-01, -6.80524707e-01,  4.92085144e-02,\n",
       "        -5.55697121e-02,  5.20477653e-01,  6.32731259e-01,\n",
       "        -5.52686527e-02,  1.75120339e-01,  4.20179874e-01,\n",
       "        -5.00471771e-01,  7.87870884e-01, -2.25993052e-01,\n",
       "         2.28513256e-01,  1.84950903e-01, -2.66342759e-01,\n",
       "        -2.98297387e-02, -4.53033984e-01, -3.82886380e-01,\n",
       "        -3.42170149e-01,  3.06111604e-01,  9.52232908e-03,\n",
       "         3.92984897e-01,  1.86551027e-02, -7.44357944e-01,\n",
       "        -7.31557548e-01, -9.65737700e-02,  1.36271771e-02,\n",
       "         4.99074049e-02,  9.58007947e-02,  3.05083811e-01,\n",
       "         1.30022215e-02, -8.71823370e-01,  1.13877868e-02,\n",
       "        -4.82452899e-01,  1.21730506e-01,  3.47316489e-02,\n",
       "        -3.11360266e-02, -5.27576566e-01,  1.19330063e-01,\n",
       "         5.38086236e-01, -5.66414416e-01,  3.49683911e-01,\n",
       "        -1.58600673e-01,  2.16271013e-01,  1.74324408e-01,\n",
       "        -1.63855795e-02, -5.49721420e-01,  1.63421810e-01,\n",
       "         1.23981848e-01,  7.88457319e-02, -1.75404534e-01,\n",
       "        -1.56997647e-02,  3.64061557e-02,  3.73822093e-01,\n",
       "         1.88174427e-01, -6.63909435e-01, -2.12167248e-01,\n",
       "         5.37607908e-01, -7.85633683e-01,  3.90950829e-01,\n",
       "         2.50270039e-01,  2.20493272e-01, -6.11000896e-01,\n",
       "         3.82155120e-01, -3.60373080e-01, -3.90548617e-01,\n",
       "         2.41815910e-01, -4.12630051e-01, -4.04933512e-01,\n",
       "         3.33754974e-03, -7.01289535e-01,  3.25644553e-01,\n",
       "        -5.08728445e-01, -1.29869729e-02,  4.45829362e-01,\n",
       "         3.17061186e-01,  5.35604119e-01, -1.42791003e-01,\n",
       "        -3.28602552e-01, -2.53798097e-01, -4.08449292e-01,\n",
       "        -1.72249973e-04,  1.03451684e-01,  7.47710690e-02,\n",
       "        -4.86083217e-02,  5.37577927e-01, -2.01556534e-01,\n",
       "        -4.56001222e-01,  6.18168890e-01,  3.68321128e-02,\n",
       "        -3.79321545e-01,  1.70565471e-01, -2.45358780e-01,\n",
       "        -2.75550544e-01,  4.94157784e-02,  1.68962091e-01,\n",
       "        -3.25813621e-01, -1.36402585e-02, -2.71743655e-01,\n",
       "        -5.58910072e-01, -2.48277292e-01, -1.52111411e-01,\n",
       "        -5.03403664e-01,  3.85462165e-01, -3.86969715e-01,\n",
       "        -7.30172276e-01,  2.48653054e-01, -1.49389088e-01,\n",
       "         3.97771932e-02, -2.67232150e-01, -2.41184652e-01,\n",
       "        -1.55596554e-01,  4.55930442e-01,  7.14731738e-02,\n",
       "         6.33400083e-02, -3.25642020e-01,  2.78999895e-01,\n",
       "        -9.34037790e-02,  2.95896828e-01, -4.07117546e-01,\n",
       "         5.62443852e-01, -1.27306789e-01,  1.88262448e-01,\n",
       "         2.52239257e-01, -3.69095802e-01, -4.59934860e-01,\n",
       "        -4.56517607e-01,  2.95720935e-01,  2.80801624e-01,\n",
       "        -2.49498203e-01, -6.98010266e-01, -5.35210371e-01,\n",
       "        -6.44334108e-02, -9.13708687e-01, -5.18231690e-01,\n",
       "         6.44367218e-01, -4.03593838e-01, -5.79679869e-02,\n",
       "        -4.79787678e-01, -6.54870152e-01,  9.03726742e-02,\n",
       "         8.15852165e-01, -5.32778740e-01, -5.35848320e-01,\n",
       "         8.49232316e-01, -3.44039738e-01,  4.68837768e-01,\n",
       "         1.71300992e-02, -5.72232902e-01, -7.72253051e-02,\n",
       "        -5.34383476e-01, -1.95447177e-01, -1.81485757e-01,\n",
       "         8.44339490e-01,  1.23798782e-02, -1.76823214e-01,\n",
       "         1.82968408e-01, -1.88562512e-01, -1.27786636e-01,\n",
       "        -1.58843935e-01,  3.19612771e-01,  3.75429899e-01,\n",
       "        -4.27378863e-01,  2.62701064e-01, -8.76287520e-01,\n",
       "        -5.35683811e-01,  4.17523384e-02, -2.54463702e-01,\n",
       "         3.83517683e-01, -1.40419766e-01, -4.35415328e-01,\n",
       "        -2.60768861e-01,  2.77793378e-01, -6.12753391e-01,\n",
       "         7.61573911e-01,  1.68721348e-01, -3.34981322e-01,\n",
       "         7.95844272e-02,  5.95397316e-02, -1.62853196e-01,\n",
       "         6.23773277e-01,  4.73847352e-02, -5.79199374e-01,\n",
       "         5.53635120e-01,  5.34690201e-01, -5.73665023e-01,\n",
       "         6.81087434e-01,  5.33858240e-01,  3.06761544e-02,\n",
       "         5.47892749e-01, -2.09042296e-01, -3.47300559e-01,\n",
       "        -6.87743604e-01,  4.54025149e-01, -3.31722319e-01,\n",
       "        -3.46041054e-01,  4.46902454e-01,  6.08720124e-01,\n",
       "         6.44495547e-01,  1.46734908e-01, -3.38314742e-01,\n",
       "        -4.59991544e-01,  3.14708650e-01,  5.45531511e-01,\n",
       "        -7.67511249e-01, -2.96969235e-01, -7.60215104e-01,\n",
       "        -5.27116060e-01,  4.23657537e-01,  4.21423972e-01,\n",
       "         1.62587792e-01, -2.35111952e-01, -5.89286983e-01,\n",
       "         4.50920194e-01,  4.97258216e-01, -4.48361225e-02,\n",
       "        -5.88490069e-01, -1.89354539e-01,  4.31503177e-01,\n",
       "        -7.65295982e-01, -6.06233239e-01,  1.56487420e-01,\n",
       "         1.14921927e-01,  1.62112936e-01, -4.03260514e-02,\n",
       "         7.00837374e-01, -3.13129984e-02,  1.17780603e-01,\n",
       "         7.78923392e-01,  2.27782354e-02,  1.09949447e-02,\n",
       "         2.22346649e-01, -1.51256397e-01, -1.41003162e-01,\n",
       "         1.53688431e-01, -2.89707690e-01, -3.38852525e-01,\n",
       "        -3.69439065e-01, -6.35629416e-01, -1.46185443e-01,\n",
       "         7.25909889e-01, -3.30466866e-01, -6.97921216e-01,\n",
       "        -7.02641547e-01, -4.17879783e-03, -8.48519444e-01,\n",
       "        -3.37337375e-01, -4.25017118e-01,  4.01198268e-01,\n",
       "        -1.37735039e-01,  2.34081969e-01,  6.46194875e-01,\n",
       "         1.45366147e-01, -1.14783077e-02, -2.24402308e-01,\n",
       "        -5.26476383e-01, -3.38403791e-01, -1.37577869e-03,\n",
       "        -4.15200800e-01,  5.76032363e-02,  2.57776558e-01,\n",
       "        -7.70987794e-02,  5.34817457e-01,  5.59613168e-01,\n",
       "         2.55602486e-02,  1.10241786e-01,  4.94584382e-01,\n",
       "        -1.98300913e-01,  7.30965853e-01, -3.43133032e-01,\n",
       "         7.59217739e-02, -1.50717404e-02,  2.55397141e-01,\n",
       "        -6.75116599e-01,  3.75019044e-01, -3.36984247e-01,\n",
       "         4.99647200e-01, -1.66619480e-01,  2.70380471e-02,\n",
       "         1.05955750e-01, -4.41049099e-01,  1.40223697e-01,\n",
       "        -3.24168615e-02,  3.33203524e-02, -4.35552746e-01,\n",
       "        -5.10639489e-01, -7.54552364e-01,  4.67864394e-01,\n",
       "        -1.85467616e-01, -7.22681358e-02,  4.59003031e-01,\n",
       "        -2.63320327e-01,  9.95939896e-02, -1.62576452e-01,\n",
       "        -4.85808045e-01,  3.48193467e-01, -2.39486545e-01,\n",
       "        -1.59544960e-01,  1.05424121e-01, -7.17502013e-02,\n",
       "         1.88185528e-01,  7.87896454e-01,  6.68727517e-01,\n",
       "         2.89963275e-01, -3.40086445e-02, -1.88488379e-01,\n",
       "         8.18846166e-01, -2.12901652e-01,  2.23087892e-03,\n",
       "        -9.22904536e-02, -2.48272032e-01, -2.52158977e-02,\n",
       "        -6.21208608e-01,  7.96596229e-01, -1.38576999e-01,\n",
       "         2.00645879e-01, -7.94968486e-01,  8.51631463e-01,\n",
       "         1.42236874e-01, -4.60342914e-02, -3.52871835e-01,\n",
       "        -9.24282730e-01,  2.14836616e-02,  5.84178090e-01,\n",
       "        -5.04782915e-01, -4.98819619e-01,  1.16197787e-01,\n",
       "         3.21129024e-01,  5.83838820e-02,  3.70487005e-01,\n",
       "        -1.07026011e-01, -6.67460203e-01, -1.13128714e-01,\n",
       "        -3.58339965e-01,  6.91385984e-01, -7.04620332e-02,\n",
       "         2.46137336e-01, -3.11714381e-01, -1.86538860e-01,\n",
       "        -2.70061731e-01, -1.65062681e-01,  7.70140588e-01,\n",
       "         4.42559153e-01, -2.84239233e-01, -3.16933692e-02,\n",
       "         2.58180290e-01, -5.11246443e-01, -1.44760475e-01,\n",
       "        -1.05525725e-01, -2.91415125e-01,  2.80844420e-01,\n",
       "         7.00787604e-01, -2.61088572e-02,  2.65722096e-01,\n",
       "         3.45026821e-01,  5.10132432e-01, -2.53897816e-01,\n",
       "        -7.90776610e-01, -2.25636035e-01, -1.90188050e-01,\n",
       "        -8.15303475e-02, -3.94110590e-01, -7.18634576e-02,\n",
       "        -6.37864888e-01, -4.53266352e-01, -4.30161029e-01,\n",
       "        -5.08890510e-01, -1.72830835e-01,  3.36901277e-01,\n",
       "         9.46336314e-02,  6.28216863e-02, -9.74035487e-02,\n",
       "         4.49461013e-01,  2.97752786e-02, -2.34732255e-01,\n",
       "        -1.74688578e-01,  3.86527807e-01,  4.63079542e-01,\n",
       "        -4.41644192e-01,  1.82656363e-01, -4.98461396e-01,\n",
       "         5.43988287e-01, -9.10176709e-02, -1.40772248e-02,\n",
       "        -1.80102840e-01, -1.71490550e-01,  2.25953519e-01,\n",
       "        -5.15595198e-01, -6.34371862e-02, -1.02916308e-01,\n",
       "        -2.64632046e-01,  3.05452067e-02, -4.12881821e-01,\n",
       "        -5.44470623e-02,  2.08236277e-02, -1.42463103e-01,\n",
       "         6.77642584e-01, -5.52943088e-02, -1.52281195e-01,\n",
       "         2.06792176e-01, -2.11747706e-01,  2.00114265e-01,\n",
       "        -2.67605215e-01, -2.81767726e-01, -3.01500946e-01,\n",
       "        -4.25988734e-01, -6.94719732e-01,  1.92486063e-01,\n",
       "        -6.68166876e-02, -4.11947146e-02,  3.84342641e-01,\n",
       "         1.86444715e-01,  1.12193383e-01, -4.13501203e-01,\n",
       "        -3.98648679e-01,  1.21542417e-01, -2.68391520e-01,\n",
       "        -5.66197932e-02,  1.25440508e-01,  5.71234286e-01,\n",
       "        -1.29199438e-02, -3.16120744e-01,  1.78043358e-03,\n",
       "        -1.10591345e-01,  4.91875634e-02, -3.89325432e-02,\n",
       "         4.91270036e-01,  5.32567501e-05,  4.84324247e-02,\n",
       "        -3.27299356e-01, -4.80608702e-01,  3.14495295e-01,\n",
       "         4.63415742e-01,  6.29338205e-01, -4.06706750e-01,\n",
       "        -2.50636756e-01,  2.75421888e-01,  3.89458299e-01,\n",
       "        -2.37221308e-02, -2.16332600e-01, -3.70431989e-01,\n",
       "        -3.98656994e-01, -7.93032497e-02,  4.91398394e-01,\n",
       "        -9.68249142e-02, -3.05019736e-01, -1.75053880e-01,\n",
       "        -2.04623267e-01, -9.27544460e-02,  6.51237667e-02,\n",
       "        -7.55718648e-01,  4.68989015e-01,  6.58009171e-01,\n",
       "         1.60806790e-01,  1.76859777e-02, -6.20126009e-01,\n",
       "         7.33746171e-01,  3.29626590e-01, -8.61394703e-01,\n",
       "         1.85550619e-02, -1.68656200e-01, -3.02162528e-01,\n",
       "        -4.29899961e-01, -3.25860202e-01,  6.10503495e-01,\n",
       "        -1.48979366e-01, -5.17862896e-03, -3.21910381e-01,\n",
       "         3.43883894e-02,  3.79301935e-01, -2.31504098e-01,\n",
       "        -2.74239630e-01,  1.40432864e-01, -1.07756503e-01,\n",
       "         3.07795197e-01, -4.88534512e-04,  1.81017548e-01,\n",
       "         4.01826411e-01, -2.96509147e-01,  4.63384122e-01,\n",
       "         1.30194381e-01, -4.51605052e-01, -1.08814359e-01,\n",
       "         1.66390374e-01,  3.34822983e-01,  4.48836833e-02]], dtype=float32))]), align=Ragged(data=array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]], dtype=int32), lengths=array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), data_shape=(-1,), starts_ends=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.trf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: The\n",
      "Lema: the\n",
      "POS: DET\n",
      "Tag: DT\n",
      "Forma: Xxx\n",
      "Es alpha: True\n",
      "Es stopword: True\n",
      "Token padre: cat\n",
      "Relaci√≥n sint√°ctica: det\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(\"Texto:\", token.text)\n",
    "print(\"Lema:\", token.lemma_)\n",
    "print(\"POS:\", token.pos_)\n",
    "print(\"Tag:\", token.tag_)\n",
    "print(\"Forma:\", token.shape_)\n",
    "print(\"Es alpha:\", token.is_alpha)\n",
    "print(\"Es stopword:\", token.is_stop)\n",
    "print(\"Token padre:\", token.head)\n",
    "print(\"Relaci√≥n sint√°ctica:\", token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lema</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "      <th>shap</th>\n",
       "      <th>isalpha</th>\n",
       "      <th>isstop</th>\n",
       "      <th>padre</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>cat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cat</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sat</td>\n",
       "      <td>sit</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peacefully</td>\n",
       "      <td>peacefully</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sat</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>mat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mat</td>\n",
       "      <td>mat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>on</td>\n",
       "      <td>pobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token        lema    POS  tag  shap  isalpha  isstop padre     dep\n",
       "0         The         the    DET   DT   Xxx     True    True   cat     det\n",
       "1       black       black    ADJ   JJ  xxxx     True   False   cat    amod\n",
       "2         cat         cat   NOUN   NN   xxx     True   False   sat   nsubj\n",
       "3         sat         sit   VERB  VBD   xxx     True   False   sat    ROOT\n",
       "4  peacefully  peacefully    ADV   RB  xxxx     True   False   sat  advmod\n",
       "5          on          on    ADP   IN    xx     True    True   sat    prep\n",
       "6         the         the    DET   DT   xxx     True    True   mat     det\n",
       "7         mat         mat   NOUN   NN   xxx     True   False    on    pobj\n",
       "8           .           .  PUNCT    .     .    False   False   sat   punct"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(\n",
    "    columns=[\"token\", \"lema\", \"POS\", \"tag\", \"shap\", \"isalpha\", \"isstop\", \"padre\", \"dep\"],\n",
    "    data=[[token.text, token.lemma_, token.pos_, token.tag_,\n",
    "          token.shape_, token.is_alpha, token.is_stop, token.head, token.dep_]\n",
    "          for token in doc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a1ac29c1629949baa871ad09c6fd182b-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">black</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">peacefully</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">mat.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a1ac29c1629949baa871ad09c6fd182b-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a1ac29c1629949baa871ad09c6fd182b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
